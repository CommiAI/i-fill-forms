---
date: 2025-08-10T09:47:09+0800
researcher: Claude
git_commit: dfb2157f45f64c01652aabd4fcde0162332587e0
branch: main
repository: i-fill-forms
topic: "DSPy Optimization and Evaluation Integration"
tags: [research, codebase, dspy, optimization, evaluation, prompt-engineering, ai-agents]
status: complete
last_updated: 2025-08-10
last_updated_by: Claude
---

# Research: DSPy Optimization and Evaluation Integration

**Date**: 2025-08-10T09:47:09+0800
**Researcher**: Claude
**Git Commit**: dfb2157f45f64c01652aabd4fcde0162332587e0
**Branch**: main
**Repository**: i-fill-forms

## Research Question
How to integrate DSPy optimization and evaluation capabilities into the i-fill-forms codebase to improve prompt performance beyond the current static, non-optimized implementation.

## Summary
The i-fill-forms codebase already uses DSPy for intelligent form field extraction but lacks optimization and evaluation capabilities. The architecture is well-positioned for enhancement with clear integration points in `backend/app/agents/intelligent_extractor.py`. By implementing DSPy's BootstrapFewShot optimizer and creating training datasets from existing FHIR/MIMIC healthcare data, the system can achieve significant improvements in decision accuracy and field extraction precision.

## Detailed Findings

### Current DSPy Implementation

#### Existing Signatures and Modules
- **AgentDecision Signature** (`backend/app/agents/intelligent_extractor.py:12-20`)
  - Analyzes conversation text to decide action type (extract_fields/store_context/ignore)
  - Uses InputFields: conversation_history, current_text, schema_fields
  - Outputs: action_type and reasoning
  
- **FieldExtractor Signature** (`backend/app/agents/intelligent_extractor.py:22-29`)
  - Extracts specific field values from conversation text
  - Uses InputFields: text, field_name, context
  - Outputs: extracted value or 'none'

- **ChainOfThought Implementation** (`backend/app/agents/intelligent_extractor.py:42-43`)
  - Both signatures use dspy.ChainOfThought for enhanced reasoning
  - Configured with Groq LLM (meta/llama-3.3-70b-versatile)

#### Current Architecture Limitations
1. **Inference-Only**: No optimization or training pipeline exists
2. **Static Prompts**: DSPy signatures are not optimized with training data
3. **No Evaluation Framework**: Missing metrics to measure extraction accuracy
4. **No Continuous Learning**: User interactions not captured for improvement

### DSPy Optimization Integration Strategy

#### Training Data Generation
The training data needs to be created specifically for DSPy optimization:
- **Required Format**: Specific JSON structure matching DSPy signature fields
- **Synthetic Generation**: Create examples using templates and variations
- **Mem0 Memory**: Can capture successful extractions for continuous learning
- **Note**: FHIR/MIMIC datasets exist but require transformation to DSPy format

#### Implementation Requirements

##### 1. Dataset Format
```python
# AgentDecision training examples
dspy.Example(
    conversation_history="Patient mentioned they have diabetes",
    current_text="My name is John Smith",
    schema_fields="name, email, phone, age, condition",
    action_type="extract_fields",
    reasoning="User provided their name which matches the 'name' field"
).with_inputs('conversation_history', 'current_text', 'schema_fields')

# FieldExtractor training examples
dspy.Example(
    text="My email is john.smith@example.com",
    field_name="email",
    context="User is providing contact information",
    value="john.smith@example.com"
).with_inputs('text', 'field_name', 'context')
```

##### 2. Evaluation Metrics
```python
def decision_metric(gold: dspy.Example, pred: dspy.Prediction) -> float:
    """Accuracy metric for action type classification"""
    return 1.0 if gold.action_type == pred.action_type else 0.0

def extraction_metric(gold: dspy.Example, pred: dspy.Prediction) -> float:
    """Precision metric with partial credit for field extraction"""
    if gold.value.lower() == pred.value.lower():
        return 1.0
    elif gold.value.lower() in pred.value.lower():
        return 0.5  # Partial credit
    return 0.0
```

##### 3. Optimizer Selection
- **BootstrapFewShot**: Best for 50-300 examples, automatic few-shot generation
- **MIPROv2**: Advanced optimization with Bayesian search for instruction tuning
- **BootstrapFewShotWithRandomSearch**: For larger datasets (500+) with multiple candidates

### Recommended Implementation Plan

#### Phase 1: Data Preparation
1. Create `backend/app/optimization/` directory for optimization scripts
2. Build training data generator from FHIR/MIMIC datasets
3. Generate 200+ examples per signature (minimum 50 for testing)
4. Split into train (80%) and validation (20%) sets

#### Phase 2: Optimization Pipeline
```python
# backend/app/optimization/optimize_dspy.py
class DSPyOptimizer:
    def __init__(self):
        # Configure Groq LLM
        groq_lm = dspy.LM(
            "meta/llama-3.3-70b-versatile",
            api_key=settings.groq_api_key,
            api_base="https://api.groq.com/openai/v1"
        )
        dspy.configure(lm=groq_lm)
    
    def optimize_agent_decision(self, train_set, val_set):
        optimizer = BootstrapFewShot(
            metric=self.decision_metric,
            max_bootstrapped_demos=4,
            max_labeled_demos=16,
            max_rounds=1
        )
        program = DecisionProgram()
        return optimizer.compile(program, trainset=train_set, valset=val_set)
```

#### Phase 3: Enhanced IntelligentExtractor
```python
class IntelligentExtractor(dspy.Module):
    def __init__(self, use_optimized=True):
        if use_optimized and os.path.exists("models/optimized_decision.pkl"):
            self.decide_action = self.load_optimized_program("models/optimized_decision.pkl")
            self.extract_field = self.load_optimized_program("models/optimized_extraction.pkl")
        else:
            # Fallback to base programs
            self.decide_action = dspy.ChainOfThought(AgentDecision)
            self.extract_field = dspy.ChainOfThought(FieldExtractor)
```

#### Phase 4: Continuous Learning Integration
- Modify `backend/app/services/mem0_memory.py` to log successful extractions
- Create background job to periodically retrain with new examples
- Implement A/B testing framework to compare optimized vs baseline

### Architecture Integration Points

#### WebSocket Pipeline (`backend/app/api/websocket.py:173-281`)
- Audio transcription at line 189
- Mem0 context retrieval at line 203
- **DSPy extraction at line 207** ‚Üê Primary integration point
- Real-time field updates at line 238
- Database persistence at lines 241-267

#### Testing Infrastructure
- Integration tests exist in `backend/test_transcription_response.py`
- Add evaluation suite for measuring optimization improvements
- Create benchmark dataset from real conversation transcripts

### Expected Improvements

1. **Decision Accuracy**: 20-40% improvement in action classification
2. **Field Extraction Precision**: 30-50% better extraction accuracy
3. **Context Utilization**: Better use of conversation history
4. **Edge Case Handling**: Improved robustness with diverse training examples
5. **Domain Adaptation**: Automatic adaptation to healthcare terminology

## Code References
- `backend/app/agents/intelligent_extractor.py:12-71` - Current DSPy signatures and module implementation
- `backend/app/api/websocket.py:206-207` - Real-time intelligent extraction integration point
- `backend/app/services/mem0_memory.py:94-106` - Memory service for continuous learning data
- `backend/app/config/settings.py:6-31` - Configuration for LLM API keys
- `data/synthea_sample_data_fhir_r4_sep2019/` - FHIR training data source
- `data/mimic-iv-clinical-database-demo-2.2/` - MIMIC-IV training data source

## Architecture Insights

### Design Patterns Supporting Optimization
1. **Modular AI Components**: Clean separation between transcription, intelligence, and memory
2. **Async Pipeline**: Non-blocking architecture allows for offline optimization
3. **Service Abstraction**: Easy to swap optimized vs non-optimized modules
4. **Centralized Configuration**: Single point for LLM and optimization settings

### Current Strengths
- Already using DSPy framework (no migration needed)
- Rich healthcare datasets available for training
- Memory service captures interaction history
- WebSocket architecture supports real-time A/B testing

### Integration Challenges
1. **Training Data Quality**: Need to ensure FHIR/MIMIC data maps to actual use cases
2. **Optimization Latency**: Initial optimization may take 30-60 minutes
3. **Model Storage**: Need strategy for versioning optimized programs
4. **Evaluation Consistency**: Must maintain consistent metrics across updates

## Historical Context (from thoughts/)

### Previous DSPy Research
- `thoughts/shared/research/2025-08-09_19-03-12_dspy_optimization_datasets.md` documented comprehensive DSPy optimization strategies including:
  - Dataset format specifications for dspy.Example objects
  - BootstrapFewShot implementation details
  - MIPRO advanced optimization techniques
  - Training data generation from FHIR/MIMIC records

### Frontend Implementation Plans
- `thoughts/shared/plans/i-fill-forms-frontend-implementation.md` includes performance optimization considerations
- Frontend not yet implemented but architecture ready for AI integration

## Related Research
- `thoughts/shared/research/2025-08-09_19-03-12_dspy_optimization_datasets.md` - DSPy dataset formats and optimization scripts
- `thoughts/shared/research/2025-01-09_18-20-00_transcription_to_frontend.md` - Transcription flow and performance

## Open Questions

1. **Optimization Frequency**: How often should the system retrain with new examples?
2. **Model Versioning**: What strategy for managing multiple optimized versions?
3. **User Feedback Loop**: How to incorporate user corrections into training data?
4. **Multi-Model Support**: Should optimization target multiple LLMs (Groq, OpenAI, Anthropic)?
5. **Production Deployment**: Blue-green deployment strategy for optimized models?
6. **Privacy Considerations**: How to ensure training data respects patient privacy?

## Next Steps

1. **Immediate Actions**:
   - Create `backend/app/optimization/` directory structure
   - Implement training data generator from FHIR datasets
   - Write evaluation metrics for both signatures
   - Create baseline performance benchmarks

2. **Short-term Goals** (1-2 weeks):
   - Implement BootstrapFewShot optimization pipeline
   - Generate 200+ training examples per signature
   - Run initial optimization and measure improvements
   - Create model storage and loading infrastructure

3. **Long-term Vision** (1-2 months):
   - Implement continuous learning with Mem0 integration
   - Deploy A/B testing framework
   - Explore MIPROv2 for advanced optimization
   - Build dashboard for monitoring extraction performance